#   流场反演的一些记录

**记录科研道路上的一些坑和经验**

markdown 中插入代码块用代码用三个反引号```，然后回车，这时就会出现代码框，选择语言类型。  

分割线用三个*

引用用一个大于号> 

***

##   4.13，网络构型

**两层全连接+BN+ELU+5层(deconv+BN+ELU)+conv+elu+2层(conv+BN+ELU)+avg_pool+3层(conv+BN+ELU)+avg_pool+2层fully+drop_out0.4**

batch=128  图片尺寸为原图*0.8   灰度图   **pool的步长为2**    learning rate = 0.6    

这种情况下，损失大约在90-100之间。此时网络的参数已经收敛了。

![fully参数变化](./记录的一些图/fully_4_13.jpg)

![conv1and2](E:\PycharmProjects\CNN\记录的一些图\conv1and2_4_13.jpg)

![](E:\PycharmProjects\CNN\记录的一些图\conv3and4_4_13.jpg)

![卷积层参数变化](E:\PycharmProjects\CNN\记录的一些图\conv5and6_4_13.jpg)

![Linear](E:\PycharmProjects\CNN\记录的一些图\linear_4_13.jpg)

![](E:\PycharmProjects\CNN\记录的一些图\deconv3and4_4_13.jpg)

**以上是这种网络结构下，参数的收敛情况，可以看到，收敛速度是很快的，但是损失最后稳定在90-100之间，就损失表现而言，是不太好的。但是考虑到此时图片的尺寸变大了，损失大一点，也是可以理解的，但是生成图片，来看效果的话，是不好的，看不出图片之间的变化！！！**

**以后要把每次训练的损失数据保存下来，不要随意删掉**

**_修改网络，继续训练，看效果如何_**

***

## 4.14

网络构型为：2层fully+BN+ELU+6层（deconv+BN+ELU）+6times(conv+BN+ELU)+AVG_POOL+2times_fully, pool的步长为1，没有drop_out。

**deconv最后一层的激活函数式tanh.**



卷积层的深度从4开始。

**此时的损失在1100左右，损失值有点高。看起来损失有点大，但是！！！每张图片是不一样的，可以看出来分离区前缘的移动了！！！又是一个大的进步。**

**2250张和第2张，可以明显看出分离区前缘的移动过程！！！**

之前pool的步长是2，效果不好，这次的步长是1，效果比较好。从实做的效果来看，**平均池化的步长为1的效果是比较好的。**

fully层中的drop_out是没有太大必要的。

![fully](E:\PycharmProjects\CNN\记录的一些图\fully_4_14.jpg)

![](E:\PycharmProjects\CNN\记录的一些图\conv1and2_4_14.jpg)

![](E:\PycharmProjects\CNN\记录的一些图\conv3and4_4_14.jpg)

![](E:\PycharmProjects\CNN\记录的一些图\conv5and6_4_14.jpg)

![](E:\PycharmProjects\CNN\记录的一些图\linear_4_14.jpg)

  ![](E:\PycharmProjects\CNN\记录的一些图\deconv3and4_4_14.jpg)

**从参数收敛的过程来看，此时，参数收敛是比较变化剧烈的，最后都能达到收敛**

**_总结：_**

**4.14的结果是比较好的！！！！**

**遇到work element count  Aborted的问题，是因为网络中的channel dim出现了0，仔细检查就能发现**

**_修改网络，继续训练，增加了一层deconv和conv，观察效果如何_**

##  4.15

**计算到最后，损失在70-80之间，比之前的效果好多了，在同样的图像尺寸的前提下，损失值更小了**

目前的网络构型是：

2层linear+BN+ELU+7times(deconv+BN+ELU),最后一层的激活函数是tanh + 7times(conv+BN+ELU)+avg_pool,步长为1  + 2层fully,没有drop_out!

卷积层的channel数从2开始。

![](E:\PycharmProjects\CNN\记录的一些图\conv1and2_4_15.jpg)

![](E:\PycharmProjects\CNN\记录的一些图\conv3and4_4_15.jpg)

![](E:\PycharmProjects\CNN\记录的一些图\conv5and6_4_15.jpg)

![](E:\PycharmProjects\CNN\记录的一些图\conv7_4_15.jpg)

![](E:\PycharmProjects\CNN\记录的一些图\linear_4_15.jpg)

![](E:\PycharmProjects\CNN\记录的一些图\deconv3and4_4_15.jpg)

![](E:\PycharmProjects\CNN\记录的一些图\deconv6and7_4_15.jpg)

![](E:\PycharmProjects\CNN\记录的一些图\fully_4_15.jpg)

**发现，最后两层fully的权重最后的偏置和标准差都是趋于0，意味着这个矩阵就是0.**

**参数收敛同样也是比较剧烈的**

**目前保存图像的函数，使用的是opencv，尝试使用一下scipy.misc.imsave()这个函数**

从保存图像的效果来看，效果也可以。能看出分离区前缘移动的过程。

**_但是，存在一个非常严重的问题！！！_**

**_从同一张图像对比着来看_**

![网络预测图](E:\PycharmProjects\CNN\prediction_test_images_4_15_opencv\test_1_batch_6.jpg)



![](E:\PycharmProjects\pictures\test_images_gray_resize\6.jpg)

**_同一个压力下的纹影图，第一张图是网络预测图，第二张图片是原图。从图中可以看出，分离区前缘识别不够准确，存在将前缘往前预测的问题。预测的前缘位置比原图的位置更加靠前。_**

![](E:\PycharmProjects\CNN\prediction_test_images_4_15_opencv\test_19_batch_2400.jpg)



![](E:\PycharmProjects\pictures\test_images_gray_resize\2400.jpg)

**_同一个压力下对应的纹影图，网络预测的纹影图还是不够精确。_原图中分离区前缘的位置已经很靠前了，网络预测的图中看的还不是很明显！！！！！**

尝试一下，不用opencv保存图片，看看效果如何？？？

用**scipy.misc.toimage()**函数来保存。效果好像是比用opencv好一点。

![](E:\PycharmProjects\CNN\prediction_test_images_4_15_scipy\test_1_batch_1.jpg)

![](E:\PycharmProjects\CNN\prediction_test_images_4_15_scipy\test_21_batch_2688.jpg)

![](E:\PycharmProjects\pictures\test_images_gray_resize\2688.jpg)



使用scipy保存的第一张预测图和最后一张预测图。可以看到有明显的变化，分离区前缘的移动。

**识别的精度还是不够好！！！！！**

**单纯依靠增加网络的深度可以解决吗？是否需要引入别的手段，比如说超分辨？亦或者，是否需要考虑别的训练的方法，比如说GAN？**

**不要加入drop_out**

**avg_pool的步长一定要是1**

**转置卷积的最后一层激活函数Tanh**

**对网络的结构进行了一些修改，增加了转置卷积和卷积的层数，增加了一层池化层**

**将最后fully的激活函数改成了elu**

**没有加入drop_out**

**f_dim修改为32**

进行训练，看效果如何？？？？

想加入超分辨的内容

#   4.17

修改了新的网络结构，增加了层。

8层deconv，最后一层的激活函数是tanh，8层卷积层，激活函数都是elu，接一层平均池化，步长为1.

倒数第二层的全连接函数的激活函数也是elu

从损失函数的角度来考虑，图片的大小为原图的0.8倍。损失值降到了50-60之间。

增加了层数，并且将倒数第二层全连接的激活函数改为 elu。**激活函数相比之前更加减小了**。

卷积层的channel数从2开始。

**接下来我们看一下参数的更新情况**

![](E:\PycharmProjects\CNN\记录的一些图\fully_4_17.jpg)

![](E:\PycharmProjects\CNN\记录的一些图\conv1and2_4_17.jpg)

![](E:\PycharmProjects\CNN\记录的一些图\conv3and4_4_17.jpg)

![](E:\PycharmProjects\CNN\记录的一些图\conv7and8_4_17.jpg)

![](E:\PycharmProjects\CNN\记录的一些图\linear_4_17.jpg)

![](E:\PycharmProjects\CNN\记录的一些图\deconv2and3_4_17.jpg)

![](E:\PycharmProjects\CNN\记录的一些图\deconv8_4_17.jpg)

**可以看到，转置卷积最后一层的偏置的标准差，一直是0  ！！！！！**

在损失值方面，此时表现的是最好的！

让我们看一下生成的图效果如何？

有个问题就是：

**测试集网络输出的第39张和第2688张图片，分离区的前缘的位置区别不是很大，但是原图的区别很大。这说明，我们这个网络捕捉这种特征的能力还不是足够的强。现在的网络，可以较好的捕捉第一张图片和最后一张图片之间的差别，但是再细小的特征很难捕捉**

测试集网络输出图片第一张：

![](E:\PycharmProjects\CNN\prediction_test_images_4_17\test_1_batch_1.jpg)

测试集网络输出图片最后一张：

![](E:\PycharmProjects\CNN\prediction_test_images_4_17\test_21_batch_2688.jpg)

这个分离区前缘的移动是很明显的！但是：

测试集网络输出图第39张：

![](E:\PycharmProjects\CNN\prediction_test_images_4_17\test_1_batch_39.jpg)

测试集网络输出图第39张和第2688张的分离区前缘位置的区别比较小，很微小！！！！

我们来看**原图**

![](E:\PycharmProjects\pictures\test_images_gray_resize\39.jpg)

这是测试集原图第39张。

![](E:\PycharmProjects\pictures\test_images_gray_resize\2688.jpg)

这是测试集原图第2688张。

**可以看得到，原图的差距还是很大的！！！！！！**

这就是现在的问题所在！！！！

**单纯的依靠一个网络够吗？？？？**

这个网络把工作做到80%,是否可以利用深度学习做超分辨，将剩余的工作推进到90%？？？？

接下来，入手超分辨！！！！

#    4.20

入手了超分辨，从初步的结果来看，是有不错的效果的。

**超分辨的网络结构选用ResNet.**

网络结尾的部分使用了一层平均池化。

整个超分辨的过程图像的维度没有发生变化。

优化器选用Adam，学习率需要足够的小，才合适。目前选2e-5，decay选择0.9

**来看一下测试集的图片在超分辨前后的效果对比。**

**单纯的流场重构网络，没有超分辨的测试集图片如下：**

测试集第一张。

![](E:\PycharmProjects\CNN\prediction_test_images_4_17\test_1_batch_1.jpg)

测试集第2688张

![](E:\PycharmProjects\CNN\prediction_test_images_4_17\test_21_batch_2688.jpg)

**能明显看出分离区前缘的移动，但是同时也存在着缺陷**

测试集第22张：

![](E:\PycharmProjects\CNN\prediction_test_images_4_17\test_1_batch_22.jpg)

测试集第2561张：

![](E:\PycharmProjects\CNN\prediction_test_images_4_17\test_21_batch_2561.jpg)

**注意：此时就不那么容易区分的出来分离区前缘的位置了！！！而且，靠后的分离区前缘还有点超出前面的图片**

**所以：这就是我们为什么要引入超分辨的原因。原有的网络区分的能力不够强。有的地方还需要进一步的改进**

下面，是超分辨、残差网络得到的一些超分辨的结果。同样是测试集中的数据：

超分辨测试集第一张：

![](E:\PycharmProjects\SRCNN\output_test_images_4_20_resnet\0.jpg)

超分辨测试集第2688张：

![](E:\PycharmProjects\SRCNN\output_test_images_4_20_resnet\2687.jpg)

能明显看出分离区前缘的位置！！

接下来看之前的网络无法区分的第22张和第2561张：

超分辨第22张：

![](E:\PycharmProjects\SRCNN\output_test_images_4_20_resnet\21.jpg)

超分辨第2561张：

![](E:\PycharmProjects\SRCNN\output_test_images_4_20_resnet\2560.jpg)

**现在可以明显的看出分离区前缘的移动了！！！！这就是改进！！！！**

**残差网络的超分辨是有明显的改进效果的！！！！**

#  5.23  写论文中网络修改进行的试验

-----

**对转置卷积网络进行了如下的修改**

1.  上采样的激活函数改成了RELU，最后一层的激活函数为tanh， 并且不加BN
2. 卷积层的激活函数改成了leaky RELU，第一层和最后一层不加BN
3. 卷积层和转置卷积层以及全连接层，权重的初始化的标准差改为0.02，之前是0.1
4. 初始的学习率改成了0.3， 正则化的比例改为0.001
5. 损失为mean square error，不变。

**训练结果显示：**

在45501步时，训练集的损失为**2333**，且越到后面，损失值下降的特别慢。

1.  学习率改为0.6
2. 上采样激活函数改为elu
3. 正则化比例改为0.01
4.  卷积层最后一层加上了BN
5.  上采样最后一层也加入了BN
6.  上采样最后一层激活函数仍然是Tanh



再次进行训练

**训练结果显示：**

较少的步数，损失值就达到了50-60

**结论：**

卷积层和上采样层最后一层的BN非常重要！！！！

